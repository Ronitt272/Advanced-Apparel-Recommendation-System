{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZgUeKHhy4dS"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXCLo61UHREh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a980d3f4-e597-4213-820e-bc78d45efa1a"
      },
      "source": [
        "import json   \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRXeZpW5H1AQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "b8862ac4-44a6-4454-93bb-5e7ea7c870cd"
      },
      "source": [
        " import json\n",
        " !gdown --id 1xWkZ70Fc0y0WvzI-4Iw8fbPI9hP_biZT\n",
        " with open('/content/tops_fashion.json') as f:\n",
        "      data = json.load(f)\n",
        "   "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1xWkZ70Fc0y0WvzI-4Iw8fbPI9hP_biZT \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0f0f23b6a31b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdown --id 1xWkZ70Fc0y0WvzI-4Iw8fbPI9hP_biZT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/tops_fashion.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m      \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/tops_fashion.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO_RwwMhLFZV"
      },
      "source": [
        "## Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi-0PuRjK4bE"
      },
      "source": [
        "df = pd.DataFrame(data)\n",
        "df = df.drop(['sku', 'author', 'publisher','availability', 'reviews', 'large_image_url','availability_type','small_image_url','editorial_review','model','manufacturer'], axis=1)\n",
        "df.head()\n",
        "del data\n",
        "#asin - amazon standard identification number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0tFps-zXLel"
      },
      "source": [
        "for i in range(10):\n",
        "  print(df['title'][i]);\n",
        "  plt.figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq3l767_zRNI"
      },
      "source": [
        "print('Attributes in data')\n",
        "for col in df.columns:\n",
        "  print('->',col)\n",
        "print('\\nDuplicate in data, and nan values')  \n",
        "for col in df.columns:\n",
        "  print('-> Column: {}, Total values {}, unique values {}, nan values {}'.format(col, len(df[col]), len(set(list(df[col]))),sum(df[col].isnull().values)))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6QLBqcp3Gk1"
      },
      "source": [
        "## Recommendation on basis of titles of clothes\n",
        "1. Remove all products with very few words in there title.\n",
        "2. Sort the whole data based on title (alphabetical order of title),m and then remove titles that are very similar\n",
        "3. using TFIDF(Term Frequency inverse document frequency) on Product titles to get an array representation as it gives less weightage to the words that appear often in the documents and focuses on words that are descriptive of the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxX1Y1bRJo-m"
      },
      "source": [
        "print('Total elements in the list: ', len(df))\n",
        "print('Attributes of an apparel: ', list(df.columns))\n",
        "print('Total null elements in formatter_price', sum(df['formatted_price'].isnull().values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nQGiE0Hbgn-"
      },
      "source": [
        "df = df.sort_values('title')\n",
        "df.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSzGA2cXcwH6"
      },
      "source": [
        "df.head(2) #Used this command to showcase the first two rows/entries in the database. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOLS8bbIXCFk"
      },
      "source": [
        "### **Cleaning the texts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwaxMDhOQCmU"
      },
      "source": [
        "### Remove duplicates in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viFMwpk3WNsb"
      },
      "source": [
        "df = df.drop_duplicates(subset = 'medium_image_url').reset_index().drop(['index'],axis=1)\n",
        "df = df.drop_duplicates(subset = 'title').reset_index().drop(['index'],axis=1)\n",
        "print(len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9CnSk9qW28z"
      },
      "source": [
        "### Remove null entries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aRgaALIV7J4"
      },
      "source": [
        "df =df.loc[~df['color'].isnull()]\n",
        "df =df.loc[~df['title'].isnull()]\n",
        "df =df.loc[~df['formatted_price'].isnull()]\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dGH54CgjyYB"
      },
      "source": [
        "### Remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU0E_gJXfKsN"
      },
      "source": [
        "stopwrds = list(stopwords.words('english'))\n",
        "l = list(df['title'])\n",
        "for i in range(len(df['title'])):\n",
        "  for j in range(len(stopwrds)):\n",
        "    l[i] = l[i].replace(' '+stopwrds[j]+' ',' ')\n",
        "df['title']=l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXut41KwPtVX"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<UNK>\") # if num words not provided it consider all\n",
        "tokenizer.fit_on_texts(list(df['title']))      #this is a must, to give the tokenizer an idea of the train data\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(list(df['title']))\n",
        "sequences[0]\n",
        "tok_sent = tokenizer.sequences_to_texts(sequences)\n",
        "df['title']=tok_sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKVCz-eqO-jj"
      },
      "source": [
        "for col in df.columns:\n",
        "  print('Column: {}, Total values {}, unique values {}, nan values {}'.format(col, len(df[col]), len(set(list(df[col]))),sum(df[col].isnull().values)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHEsoo7luCRw"
      },
      "source": [
        "df.reset_index(drop=True,inplace=True)\n",
        "indices = list(df.index)\n",
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wma74mou2RkL"
      },
      "source": [
        "* Removing titles that have are very similar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlK15hIJtXlJ"
      },
      "source": [
        "import itertools\n",
        "deduped_idx = []\n",
        "i = 0\n",
        "j = 0 \n",
        "while i < len(df) and j < len(df):\n",
        "    previous_i = i\n",
        "    a = df['title'].loc[i].split()\n",
        "    j = i+1\n",
        "    while j < len(df):\n",
        "        b = df['title'].loc[indices[j]].split()\n",
        "        length = max(len(a), len(b))\n",
        "        count  = 0\n",
        "        for k in itertools.zip_longest(a,b): \n",
        "            if (k[0] == k[1]):\n",
        "                count += 1\n",
        "        if (length - count) > 2: \n",
        "            deduped_idx.append(i)\n",
        "            i = j\n",
        "            break\n",
        "        else:\n",
        "            j += 1\n",
        "    if previous_i == i:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_2rd6Yx6MOU"
      },
      "source": [
        "df = df.iloc[deduped_idx]\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "df.head(2)\n",
        "list_titles = list(df['title'])\n",
        "print(len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxZeZ2VGVJ6-"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooJCvEgqNqAg"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer\n",
        "X = vectorizer.fit_transform(list_titles) #corpus is a list tof sentences\n",
        "analyze = vectorizer.build_analyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k7eLjZQP8_Y"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(list_titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIfxeud1P9Rw"
      },
      "source": [
        "def closestkrecom(idx,k):\n",
        "  dist = sklearn.metrics.pairwise_distances( X, X[idx], metric='cosine')\n",
        "  dist = np.squeeze(dist)\n",
        "  #print(dist.shape)\n",
        "  sort_idxs = np.random.choice(np.argsort(dist,axis=0)[1:],k)\n",
        "  return sort_idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql3BpKFyyyGl"
      },
      "source": [
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqfX1YLeP9aF"
      },
      "source": [
        "for idx in random.sample(list(np.arange(len(df))), 20):\n",
        "  print('-->  ', df['title'][idx])\n",
        "  for j in closestkrecom(idx,5):\n",
        "    print('   ',df['title'][j])\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mvdHr4G4tsP"
      },
      "source": [
        "## Recommendation on basis of image\n",
        "* I am going to use an autoencoder and get a 2000 dimensional embedding\n",
        "* Then \n",
        "\n",
        "\n",
        "\n",
        "![link text](https://miro.medium.com/max/3148/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azSm0YN57UVn"
      },
      "source": [
        "### Imports and downloading the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwxqnYa7gOYi"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import skimage\n",
        "from skimage import io\n",
        "import urllib.request\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCzLuu568ODd"
      },
      "source": [
        "path =  \"/content/drive/My Drive/Apparel Reco\"\n",
        "try:\n",
        "  os.makedirs('/content/Dataset/Train/Sample')                 #better than mkdir\n",
        "except OSError:\n",
        "  pass\n",
        "try:\n",
        "  os.makedirs('/content/Dataset/Test/Sample')                 #better than mkdir\n",
        "except OSError:\n",
        "  pass  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hico0Sqn8U_s"
      },
      "source": [
        "def download_images(df): #function to download all the images\n",
        "  j=0\n",
        "  o=0\n",
        "  train,test = train_test_split(np.arange(len(df)), test_size=0.1, )\n",
        "  for i in train:\n",
        "    try:\n",
        "      name = df['asin'][i] + \".jpg\"\n",
        "      print(name,', ',o)\n",
        "      o+=1\n",
        "      urllib.request.urlretrieve(df['medium_image_url'][i], \"/content/Dataset/Train/Sample/\"+ name)\n",
        "    except:\n",
        "      print(\"N/A\",j)\n",
        "      j+=1  \n",
        "  for i in test:\n",
        "    try:\n",
        "      name = df['asin'][i] + \".jpg\"\n",
        "      print(name,', ',o)\n",
        "      o+=1\n",
        "      urllib.request.urlretrieve(df['medium_image_url'][i], \"/content/Dataset/Test/Sample/\"+ name)\n",
        "    except:\n",
        "      print(\"N/A\",j)\n",
        "      j+=1      \n",
        "download_images(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCYKAdsQNMrh"
      },
      "source": [
        "def disp_img(idx): #this function displays image from idx in df\n",
        "  response = requests.get(df['medium_image_url'][idx])\n",
        "  img = Image.open(BytesIO(response.content))\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC0L5gBszu2w"
      },
      "source": [
        "def ur2arr(url, disp=False): #This takes in an url and convert it to array\n",
        "  image_filename = url\n",
        "  image_numpy = skimage.io.imread(image_filename)\n",
        "  if disp:\n",
        "    plt.imshow(image_numpy)\n",
        "  return image_numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2KmMI2E8iPG"
      },
      "source": [
        "### Creating the Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvnYheGvm036"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255)\n",
        "train_generator = train_datagen.flow_from_directory(                        #here we fit the data to the generator\n",
        "        '/content/Dataset/Train',  # This is the source directory for training images\n",
        "        target_size=(128, 128),  # All images will be resized to 150x150, no need to provide the channel dimension\n",
        "        batch_size=64,           #labels are automatically assigned on basis of the directory they are in\n",
        "        class_mode='input')\n",
        "test_generator = test_datagen.flow_from_directory(                          #here we fit the data to the generator\n",
        "        '/content/Dataset/Test',  # This is the source directory for test images\n",
        "        target_size=(128, 128),  # All images will be resized to 150x150, no need to provide the channel dimension\n",
        "        batch_size=128,           #labels are automatically assigned on basis of the directory they are in\n",
        "        class_mode='input')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb3aOghW8pmN"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYn_1zGDXNW2"
      },
      "source": [
        "input_img = tf.keras.layers.Input(shape=(128, 128, 3))  # adapt this if using `channels_first` image data format\n",
        "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "encoder = tf.keras.Model(input_img, tf.keras.layers.Flatten()(encoded))\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(16, (1, 1), activation='relu')(x)\n",
        "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "decoded = tf.keras.layers.UpSampling2D((1, 1))(x)\n",
        "autoencoder = tf.keras.Model(input_img, decoded)\n",
        "autoencoder.summary()\n",
        "opt = tf.keras.optimizers.Adam()\n",
        "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6b4tWmS8vTX"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjdJrUKX3R5H"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(0.01)\n",
        "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "history = autoencoder.fit(train_generator,\n",
        "                epochs=10,\n",
        "                validation_data=test_generator\n",
        "                #callbacks=[tf.keras.callbacks.LearningRateScheduler(lrs)]\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK2kJBnz9FE5"
      },
      "source": [
        "### Image Reconstruction quality check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f83aHZXAuWN"
      },
      "source": [
        "x_test = next(iter(test_generator))\n",
        "x_test[1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBA30NxLOSQk"
      },
      "source": [
        "x_test = next(iter(test_generator))[0]\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n+1):\n",
        "    if i==0:\n",
        "      continue\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(128, 128,3))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(128, 128,3))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPudvHSAYTMP"
      },
      "source": [
        "os.listdir('/content/Dataset/Train/Sample')\n",
        "p = {}\n",
        "t=0\n",
        "for filename in os.listdir('/content/Dataset/Train/Sample'):\n",
        "  img = cv2.imread(os.path.join('/content/Dataset/Train/Sample',filename))\n",
        "  img = cv2.resize(img, (128,128))\n",
        "  img = np.expand_dims(img,0)\n",
        "  p[filename] = encoder.predict(img)\n",
        "  t+=1\n",
        "  print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD-M2CQVm-h2"
      },
      "source": [
        "t=0\n",
        "for filename in os.listdir('/content/Dataset/Test/Sample'):\n",
        "  img = cv2.imread(os.path.join('/content/Dataset/Test/Sample',filename))\n",
        "  img = cv2.resize(img, (128,128))\n",
        "  img = np.expand_dims(img,0)\n",
        "  p[filename] = encoder(img)\n",
        "  t+=1\n",
        "  print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o3j8Vdssv96"
      },
      "source": [
        "from PIL import Image as PImage\n",
        "from matplotlib import rcParams\n",
        "\n",
        "def disp(l):\n",
        "  k= len(l)\n",
        "  rcParams['figure.figsize'] = 11.7,8.27\n",
        "  for i,filename in enumerate(l): \n",
        "    plt.figure(figsize =(3,3))\n",
        "    try:\n",
        "      img = PImage.open('/content/Dataset/Test/Sample/' + filename)\n",
        "      plt.imshow(img)\n",
        "    except:\n",
        "      if(i==0):\n",
        "       plt.title('Chosen Apparel')\n",
        "      # print(df['title'][i])\n",
        "      else:\n",
        "        plt.title('Recommended Apparels') \n",
        "        #plt.title((df['title'][i]))\n",
        "      img = PImage.open('/content/Dataset/Train/Sample/' + filename)\n",
        "      plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uwSIkq1VEL_"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "def closestkrecom(idx,k):\n",
        "  asin = df.iloc[idx]['asin'] + '.jpg'\n",
        "  q={}\n",
        "  arr = np.squeeze(p[asin])\n",
        "  for key, value in p.items():\n",
        "    dist = distance.cosine(arr,np.squeeze(value))\n",
        "    q[key] = dist\n",
        "  q = {value:key for key,value in q.items() } \n",
        "  l=[]\n",
        "  for j,i in enumerate(sorted(q)): \n",
        "    if j== k:\n",
        "      break  \n",
        "    l.append(str(q[i])) \n",
        "  return l "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_xeDu-mKgA-"
      },
      "source": [
        "temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSO8_Byj5C6p"
      },
      "source": [
        "temp = random.randint(0,len(df))\n",
        "l = closestkrecom(temp,10)\n",
        "disp(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zbl58yN6HE_"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer(oov_token=\"<UNK>\") \n",
        "tokenizer.fit_on_texts(list_titles)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_len = len(word_index)\n",
        "def sentence2indices(sentences):\n",
        "  sequences = tokenizer.texts_to_sequences(sentences)\n",
        "  padded = pad_sequences(sequences, maxlen=7, padding = 'post', truncating = 'post')\n",
        "  return padded\n",
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_len, 32, input_length=7),\n",
        "                             tf.keras.layers.LSTM(32),\n",
        "                             tf.keras.layers.Dense(32)])\n",
        "model.compile(loss = 'mse', optimizer = 'adam')\n",
        "model.fit(sentence2indices(list_titles),)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}